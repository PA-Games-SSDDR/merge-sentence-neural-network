{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 20:08:14.345767: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 20:08:14.818453: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 20:08:15.033742: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 20:08:16.288162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-03 20:08:16.288325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-03 20:08:16.288333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "# test_df = pd.read_csv(\"/kaggle/input/unveiling-complex-text-relations-through-splitti/test.csv\")\n",
    "# cleanse data of punctuation\n",
    "df['complex_sentence'] = df['complex_sentence'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "df['simple_sentence_1'] = df['simple_sentence_1'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "df['simple_sentence_2'] = df['simple_sentence_2'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_list = df['complex_sentence'].values.tolist()\n",
    "simpl_sent1_list = df['simple_sentence_1'].values.tolist()\n",
    "simpl_sent2_list = df['simple_sentence_2'].values.tolist()\n",
    "max_len_complex = max([len(x.split(\" \")) for x in complex_list])\n",
    "max_len_simpl_sent1 = max([len(x.split(\" \")) for x in simpl_sent1_list])\n",
    "max_len_simpl_sent2 = max([len(x.split(\" \")) for x in simpl_sent2_list])\n",
    "max_tok_size = max(max_len_complex, max(max_len_simpl_sent1, max_len_simpl_sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [complex_list[i] + \" \" + simpl_sent1_list[i] + \" \" + simpl_sent2_list[i] for i in range(len(complex_list))]\n",
    "fit_text = new_list\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(fit_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Siamese neural network architecture\n",
    "def create_siamese_network(max_sequence_length, embedding_dim, tokenizer_len):\n",
    "    # Input layer for the first sentence\n",
    "    input_a = Input(shape=(max_sequence_length,1), name='input_a')\n",
    "    \n",
    "    # Input layer for the second sentence\n",
    "    input_b = Input(shape=(max_sequence_length,1), name='input_b')\n",
    "    \n",
    "    # Shared embedding layer\n",
    "    vocabulary_size = tokenizer_len\n",
    "    # embedding_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim)\n",
    "    \n",
    "    # Shared LSTM layer\n",
    "    # lstm_layer = LSTM(128)\n",
    "    \n",
    "    # Apply embedding layer to both inputs\n",
    "    # encoded_a = embedding_layer(input_a)\n",
    "    # encoded_b = embedding_layer(input_b)\n",
    "    \n",
    "    # Encoder part\n",
    "    encoder_a = LSTM(64, activation='relu')(input_a)\n",
    "    encoder_b = LSTM(64, activation='relu')(input_b)\n",
    "    \n",
    "    # Merge the two encoded representations using a distance function (e.g., Euclidean or Manhattan)\n",
    "    # merged_layer = tf.keras.layers.Lambda(lambda x: tf.keras.backend.abs(x[0] - x[1]))([encoded_a, encoded_b])\n",
    "    merged_layer = Concatenate(axis=1, name='encoder_ab_output')([encoder_a,encoder_b])\n",
    "    \n",
    "    # Decoder part\n",
    "    decoder1 = RepeatVector(max_sequence_length)(merged_layer)\n",
    "    decoder1 = LSTM(max_sequence_length, activation='relu', return_sequences=True)(decoder1)\n",
    "    output_layer = TimeDistributed(Dense(1))(decoder1)\n",
    "    # Dense layer for the final similarity prediction\n",
    "    # output_layer = Dense(1, activation='sigmoid')(merged_layer)\n",
    "    \n",
    "    # Create the Siamese style autoencoder model\n",
    "    siamese_model = Model(inputs=[input_a, input_b], outputs=output_layer)\n",
    "    \n",
    "    siamese_model.compile(loss='mse', optimizer='adam')\n",
    "    print(siamese_model.summary())\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 20:09:18.247535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.483972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.484019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.485411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 20:09:18.486129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.486172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.486223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.754484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.755306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.755329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-03 20:09:18.755359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 20:09:18.755396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1781 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_a (InputLayer)           [(None, 51, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " input_b (InputLayer)           [(None, 51, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           16896       ['input_a[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 64)           16896       ['input_b[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_ab_output (Concatenate  (None, 128)         0           ['lstm[0][0]',                   \n",
      " )                                                                'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 51, 128)      0           ['encoder_ab_output[0][0]']      \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 51, 51)       36720       ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 51, 1)       52          ['lstm_2[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,564\n",
      "Trainable params: 70,564\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "siamese_model = create_siamese_network(max_tok_size, embedding_dim=100, tokenizer_len=len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_complex_list = tokenizer.texts_to_sequences(complex_list)\n",
    "tok_simpl_sent1_list = tokenizer.texts_to_sequences(simpl_sent1_list)\n",
    "tok_simpl_sent2_list = tokenizer.texts_to_sequences(simpl_sent2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_complex_list = pad_sequences(tok_complex_list, maxlen=max_tok_size)\n",
    "tok_simpl_sent1_list = pad_sequences(tok_simpl_sent1_list, maxlen=max_tok_size)\n",
    "tok_simpl_sent2_list = pad_sequences(tok_simpl_sent2_list, maxlen=max_tok_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598614\n",
      "598614\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.83757813883404e-05, 4.009261393819724e-05, 0.017811143742044122, 3.1739986034406146e-05, 5.8468395326537636e-05, 0.0007433838834374071, 1.002315348454931e-05, 0.0004243134975125874, 4.009261393819724e-05, 0.002804812450093048, 1.002315348454931e-05, 0.0011342868693348302, 1.6705255807582181e-06, 0.008591513061839516, 0.04204211729094207, 6.6821023230328725e-06, 0.006130828881382661, 5.011576742274655e-06, 0.0003090472324402704, 3.3410511615164364e-05, 0.00015201782784899785, 0.02171182097311456, 1.002315348454931e-05, 1.6705255807582181e-06, 0.00022719147898311767, 5.011576742274655e-06, 0.0010741479484275343, 4.343366509971367e-05, 0.007465578820408477, 6.6821023230328725e-06, 0.0023387358130615055, 0.00041763139518955454, 1.002315348454931e-05, 7.35031255533616e-05, 0.019862549155215212, 0.019984497522610563, 5.011576742274655e-06, 6.849154881108694e-05, 0.009473550568479856, 0.002243515854958287]\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.index_word))\n",
    "print(len(tokenizer.index_word.keys()))\n",
    "print([x/len(tokenizer.index_word) for x in tok_complex_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_max = len(tokenizer.index_word)\n",
    "tok_complex_list = [[[y/tok_max] for y in x] for x in tok_complex_list]\n",
    "tok_simpl_sent1_list = [[[y/tok_max] for y in x]  for x in tok_simpl_sent1_list]\n",
    "tok_simpl_sent2_list = [[[y/tok_max] for y in x]  for x in tok_simpl_sent2_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_per = int(.8 * len(tok_complex_list))\n",
    "tot = len(tok_complex_list)\n",
    "tok_complex_list_train, tok_complex_list_test = tok_complex_list[:val_per], tok_complex_list[val_per:]\n",
    "tok_simpl_sent1_list_train, tok_simpl_sent1_list_test = tok_simpl_sent1_list[:val_per], tok_simpl_sent1_list[val_per:]\n",
    "tok_simpl_sent2_list_train, tok_simpl_sent2_list_test = tok_simpl_sent2_list[:val_per], tok_simpl_sent2_list[val_per:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.fit([tok_simpl_sent1_list_train, tok_simpl_sent2_list_train], tok_complex_list_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = siamese_model.predict([tok_simpl_sent1_list_test, tok_simpl_sent2_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2695334,
     "sourceId": 4632840,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
